{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEm9ds8EfcFu8NpFH5kqS9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/randomfunction/DLcpp/blob/main/TTNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanilla Two-Tower Neural Network Arch"
      ],
      "metadata": {
        "id": "ezQQOVq4bGPl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MpI4XaSkU8py"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Tower(nn.Module):\n",
        "  def __init__(self, inputdim, embeddingdim):\n",
        "    super(Tower, self).__init__()\n",
        "    self.fc1= nn.Linear(inputdim, 256)\n",
        "    self.fc2= nn.Linear(256, 128)\n",
        "    self.fc3 = nn.Linear(128, 64 )\n",
        "    self.fc4= nn.Linear(64, embeddingdim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x= F.relu(self.fc1(x))\n",
        "    x= F.relu(self.fc2(x))\n",
        "    x= F.relu(self.fc3(x))\n",
        "    x= self.fc4(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Od5bPZJGVE-O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwotowerModel(nn.Module):\n",
        "  def __init__(self, DIM1, DIM2, embeddingdim):\n",
        "    super(TwotowerModel, self).__init__()\n",
        "    self.tower1= Tower(DIM1, embeddingdim)\n",
        "    self.tower2= Tower(DIM2, embeddingdim)\n",
        "\n",
        "  def forward(self, INPUT1, INPUT2):\n",
        "    embedding1= self.tower1(INPUT1)\n",
        "    embedding2= self.tower2(INPUT2)\n",
        "\n",
        "    #normalize\n",
        "    embedding1= F.normalize(embedding1)\n",
        "    embedding2= F.normalize(embedding2)\n",
        "\n",
        "    #similarity\n",
        "    similarity= F.cosine_similarity(embedding1, embedding2)\n",
        "\n",
        "    return embedding1, embedding2, similarity"
      ],
      "metadata": {
        "id": "_KBIUGcgXGqI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DIM1=50\n",
        "DIM2=50\n",
        "embeddingdim=10\n",
        "model= TwotowerModel(DIM1, DIM2, embeddingdim)\n",
        "INPUT1= torch.randn(10, DIM1)\n",
        "INPUT2= torch.randn(10, DIM2)\n",
        "embedding1, embedding2, similarity= model(INPUT1, INPUT2)\n",
        "print(embedding1)\n",
        "print(embedding2)\n",
        "print(similarity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2z9HxfcaImo",
        "outputId": "8f876270-1ba1-4a3f-a0f9-c626c4f94cfc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1272, -0.3198, -0.5427, -0.3400, -0.1266, -0.2701,  0.2154, -0.2980,\n",
            "         -0.1250,  0.4813],\n",
            "        [-0.3282, -0.3456, -0.6336, -0.3675, -0.0232, -0.2068,  0.2456, -0.1806,\n",
            "         -0.0957,  0.3017],\n",
            "        [-0.1893, -0.3855, -0.5091, -0.2711,  0.0639, -0.1892,  0.2393, -0.2996,\n",
            "          0.1068,  0.5335],\n",
            "        [-0.2340, -0.4451, -0.5838, -0.3110, -0.0409, -0.3466,  0.0954, -0.2687,\n",
            "          0.1082,  0.3078],\n",
            "        [-0.3668, -0.4783, -0.5141, -0.2265,  0.1370, -0.2935,  0.0894, -0.3363,\n",
            "          0.1181,  0.2846],\n",
            "        [-0.2762, -0.4620, -0.4832, -0.1888, -0.0046, -0.4247,  0.1071, -0.3500,\n",
            "          0.0187,  0.3555],\n",
            "        [-0.1930, -0.3888, -0.4973, -0.1231,  0.0364, -0.3656,  0.1993, -0.3863,\n",
            "         -0.0237,  0.4739],\n",
            "        [-0.1724, -0.4749, -0.5442, -0.2515,  0.0204, -0.2607,  0.1673, -0.2879,\n",
            "         -0.0964,  0.4435],\n",
            "        [-0.1962, -0.3255, -0.4790, -0.1768,  0.0069, -0.3213,  0.3095, -0.4265,\n",
            "         -0.0269,  0.4616],\n",
            "        [-0.2319, -0.3807, -0.4886, -0.2360,  0.0904, -0.3926,  0.1864, -0.3418,\n",
            "         -0.0334,  0.4380]], grad_fn=<DivBackward0>)\n",
            "tensor([[ 0.4941,  0.2812, -0.0412, -0.0669, -0.4965,  0.2358,  0.4922,  0.1831,\n",
            "          0.2207, -0.2097],\n",
            "        [ 0.5427,  0.0245,  0.0511,  0.0016, -0.4522,  0.2169,  0.4977, -0.0025,\n",
            "          0.2935, -0.3418],\n",
            "        [ 0.4167,  0.0145,  0.2730, -0.0721, -0.3859,  0.2913,  0.6053, -0.0864,\n",
            "          0.2688, -0.2580],\n",
            "        [ 0.4220,  0.1238,  0.2258, -0.0829, -0.4840,  0.2572,  0.4863, -0.0424,\n",
            "          0.3064, -0.3409],\n",
            "        [ 0.4964,  0.2238,  0.2609, -0.0870, -0.3271,  0.3409,  0.5577,  0.1838,\n",
            "          0.2360, -0.0646],\n",
            "        [ 0.2263,  0.3383,  0.1929, -0.0204, -0.5212,  0.3476,  0.5539,  0.0568,\n",
            "          0.2662, -0.1528],\n",
            "        [ 0.5362,  0.2380, -0.0655, -0.0176, -0.4706,  0.2343,  0.4189,  0.0638,\n",
            "          0.3781, -0.2289],\n",
            "        [ 0.4451,  0.2207,  0.2336, -0.0725, -0.4676,  0.4764,  0.4305,  0.0800,\n",
            "          0.2238, -0.0766],\n",
            "        [ 0.3796,  0.0534,  0.2202, -0.0201, -0.4587,  0.4309,  0.4592, -0.1035,\n",
            "          0.2810, -0.3280],\n",
            "        [ 0.4556,  0.0588,  0.2350, -0.0711, -0.4557,  0.2642,  0.5414, -0.1322,\n",
            "          0.1616, -0.3385]], grad_fn=<DivBackward0>)\n",
            "tensor([-0.1856, -0.2624, -0.2218, -0.3432, -0.5509, -0.4633, -0.3227, -0.4308,\n",
            "        -0.3081, -0.3785], grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Two-Tower NN arch."
      ],
      "metadata": {
        "id": "ZtMxFVzdcWQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Everything quite similar we just replace fully connected layers\n",
        "     of Tower class , with some 1D convlution layers\n",
        "\"\"\"\n",
        "\n",
        "class CNNTower(nn.Module):\n",
        "  def __init__(self, inputdim, embeddingdim):\n",
        "    super(CNNTower, self).__init__()\n",
        "    self.conv1= nn.Conv1d(inputdim, 128, kernel_size=3, padding=1)\n",
        "    self.conv2= nn.Conv1d(128, 64, kernel_size=3, padding=1)\n",
        "    self.conv3= nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
        "    self.fc4= nn.Linear(32, embeddingdim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x= F.relu(self.conv1(x))\n",
        "    x= F.relu(self.conv2(x))\n",
        "    x= F.relu(self.conv3(x))\n",
        "    x= x.view(x.size(0),-1) #flatten\n",
        "    x= self.fc4(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "2KGBL0IacbUv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN + RNN  Two-Tower NN arch."
      ],
      "metadata": {
        "id": "k8zwQbfffcYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "We can combine CNN + RNN for better accuracy as,\n",
        "CNN good at capturing local, high level features while RNN captures temporal dependencies, long term trends.\n",
        "\"\"\"\n",
        "\n",
        "class CNN_RNN_Tower(nn.Module):\n",
        "  def __init__(self, inputdim, embeddingdim):\n",
        "    super(CNN_RNN_Tower, self).__init__()\n",
        "    self.conv1= nn.Conv1d(inputdim, 128, kernel_size=3, padding=1)\n",
        "    self.conv2= nn.Conv1d(128, 64, kernel_size=3, padding=1)\n",
        "    self.conv3= nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
        "    self.rnn= nn.LSTM(32, 64, num_layers=2, batch_first=True)\n",
        "    self.fc4= nn.Linear(64, embeddingdim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x= F.relu(self.conv1(x))\n",
        "    x= F.relu(self.conv2(x))\n",
        "    x= F.relu(self.conv3(x))\n",
        "    x= x.view(x.size(0),-1) #flatten\n",
        "    x= F.relu(self.rnn(x))\n",
        "    x= self.fc4(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "XauHGAq4eE8K"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}